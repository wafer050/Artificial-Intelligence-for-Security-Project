# Artificial Intelligence for Security  
## Group Assignment â€“ Academic Year 2025/26

**Course:** Artificial Intelligence for Security  
**Assignment Type:** Group Project  
**Submission Date:** 18 December 2025  
**Presentation Date:** 19 December 2025  

---

## ðŸ“Œ Project Overview

This project was developed as part of the *Artificial Intelligence for Security* course (AY 2025/26).  
The goal of the assignment is to analyse a large, real-world cybersecurity dataset and apply **data analysis, visualization, and machine learning techniques** to extract meaningful security-related insights.

The work is implemented in a **self-contained Python notebook**, designed to clearly explain:
- the data exploration process,
- the applied methodologies,
- the obtained results, and
- the conclusions drawn from the analysis.

---

## ðŸ“‚ Selected Dataset

For this assignment, we selected the following dataset:

**Dataset of Jailbreak Attacks on Large Language Models (LLMs)**  
ðŸ“Ž https://huggingface.co/datasets/qualifire/prompt-injections-benchmark

This dataset contains:
- **benign prompts**, and
- **malicious prompts** specifically designed to perform *prompt injection* and *jailbreak attacks* on LLMs.

The dataset represents a realistic and emerging cybersecurity threat, making it highly relevant to the scope of AI security.

---

## ðŸŽ¯ Objectives

The main objectives of this project are to:

- Explore and understand the structure and characteristics of a real cybersecurity dataset
- Identify patterns that distinguish malicious prompts from benign ones
- Apply **supervised and unsupervised machine learning techniques**
- Investigate **anomaly detection** approaches
- Critically interpret the results in a cybersecurity context

---
